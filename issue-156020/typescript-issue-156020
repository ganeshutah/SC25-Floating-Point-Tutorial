Script started on 2025-07-13 13:28:40-06:00 [TERM="xterm-256color" TTY="/dev/pts/1" COLUMNS="106" LINES="42"]
[?2004h]0;ganesh@dknuth: ~/repos/pytorch/issue-156020[01;32mganesh@dknuth[00m:[01;34m~/repos/pytorch/issue-156020[00m$ LD_PRELOAD=~/nixnan.so python run.py
[?2004l------------- NVBit (NVidia Binary Instrumentation Tool v1.7.2) Loaded --------------
NVBit core environment variables (mostly for nvbit-devs):
ACK_CTX_INIT_LIMITATION = 0 - if set, no warning will be printed for nvbit_at_ctx_init()
            NVDISASM = nvdisasm - override default nvdisasm found in PATH
            NOBANNER = 0 - if set, does not print this banner
       NO_EAGER_LOAD = 0 - eager module loading is turned on by NVBit to prevent potential NVBit tool deadlock, turn it off if you want to use the lazy module loading feature
---------------------------------------------------------------------------------
         INSTR_BEGIN = 0 - Beginning of the instruction interval where to apply instrumentation
           INSTR_END = 4294967295 - End of the instruction interval where to apply instrumentation
        TOOL_VERBOSE = 0 - Enable verbosity inside the tool
   ENABLE_FUN_DETAIL = 0 - Enable detailed function information for kernel
     PRINT_ILL_INSTR = 0 - Print the instruction which caused the exception
            SAMPLING = 0 - Instrument a repeat kernel every SAMPLING times
----------------------------------------------------------------------------------
WARNING: Do not call CUDA memory allocation in nvbit_at_ctx_init(). It will cause deadlocks. Do them in nvbit_tool_init(). If you encounter deadlocks, remove CUDA API calls to debug.
#nixnan: Initializing GPU context...
#nixnan: Could not open kernel_whitelist.txt!
#nixnan: Could not open kernel_blacklist.txt!
#nixnan: instrumenting all kernels
#nixnan: running kernel [void vector_fft] ...
#nixnan: running kernel [void at::native::vectorized_elementwise_kernel] ...
#nixnan: error [infinity] detected in operand 0 of instruction FADD R0, R2.reuse, R4.reuse ; in function void vector_fft at line 0 of type f32
#nixnan: error [infinity] detected in operand 1 of instruction FSEL R11, R0, R7, !P0 ; in function void vector_fft at line 0 of type f32
#nixnan: error [infinity] detected in operand 0 of instruction FSEL R11, R0, R7, !P0 ; in function void vector_fft at line 0 of type f32
#nixnan: error [infinity] detected in operand 1 of instruction @!P0 FMUL R15, R9, c[0x0][0x174] ; in function void at::native::vectorized_elementwise_kernel at line 0 of type f32
#nixnan: error [NaN] detected in operand 0 of instruction @!P0 FMUL R15, R9, c[0x0][0x174] ; in function void at::native::vectorized_elementwise_kernel at line 0 of type f32
#nixnan: error [NaN] detected in operand 0 of instruction @!P0 FFMA R4, R8, c[0x0][0x170], -R15 ; in function void at::native::vectorized_elementwise_kernel at line 0 of type f32
tensor([0.+infj, 0.+0.j, 0.+0.j, 0.+0.j])
tensor([nan+infj, 0.+0.j, 0.+0.j, 0.+0.j])
#nixnan: Finalizing GPU context...

#nixnan: ------------ nixnan Report -----------

#nixnan: --- FP16 Operations ---
#nixnan: NaN:           0
#nixnan: Infinity:      0
#nixnan: Subnormal:     0
#nixnan: Division by 0: 0

#nixnan: --- FP32 Operations ---
#nixnan: NaN:           2
#nixnan: Infinity:      6
#nixnan: Subnormal:     0
#nixnan: Division by 0: 0

#nixnan: --- FP64 Operations ---
#nixnan: NaN:           0
#nixnan: Infinity:      0
#nixnan: Subnormal:     0
#nixnan: Division by 0: 0

[?2004h]0;ganesh@dknuth: ~/repos/pytorch/issue-156020[01;32mganesh@dknuth[00m:[01;34m~/repos/pytorch/issue-156020[00m$ exit
[?2004lexit

Script done on 2025-07-13 13:32:11-06:00 [COMMAND_EXIT_CODE="0"]
